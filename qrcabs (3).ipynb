{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Q learning cabs project source code"],"metadata":{"id":"XiLAje4FNTFM"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"xf58Ubj16zPC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694192043265,"user_tz":-330,"elapsed":10031,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"d1e52c66-161a-4a57-b012-9e1005f2e71f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym[toy_text] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[toy_text]) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[toy_text]) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[toy_text]) (0.0.8)\n","Collecting pygame==2.1.0 (from gym[toy_text])\n","  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pygame\n","  Attempting uninstall: pygame\n","    Found existing installation: pygame 2.5.1\n","    Uninstalling pygame-2.5.1:\n","      Successfully uninstalled pygame-2.5.1\n","Successfully installed pygame-2.1.0\n"]}],"source":["pip install gym[toy_text]"]},{"cell_type":"code","source":["import gym"],"metadata":{"id":"NHGNef-CmR68","executionInfo":{"status":"ok","timestamp":1694192048242,"user_tz":-330,"elapsed":724,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["env = gym.make(\"Taxi-v3\").env\n","new_step_api=True"],"metadata":{"id":"snQBHSTOmLE9","executionInfo":{"status":"ok","timestamp":1694192052401,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"94aa172c-0cf5-4549-b351-eda7f58d14c0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}]},{"cell_type":"code","source":["a = env.action_space.n\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IKcN7Lomizr","executionInfo":{"status":"ok","timestamp":1694192065666,"user_tz":-330,"elapsed":392,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"f33972d1-11d0-4977-ccc8-099905889b6b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["6\n"]}]},{"cell_type":"code","source":["env.observation_space.n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_ExA6W8msDw","executionInfo":{"status":"ok","timestamp":1694192082593,"user_tz":-330,"elapsed":411,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"edd9dc0f-6f46-42bd-b3a1-b837ea0b3cde"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["500"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["env.reset()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pNIRreJxs7x","executionInfo":{"status":"ok","timestamp":1694192187030,"user_tz":-330,"elapsed":499,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"2e04b2d5-cfc4-4f8d-f2b6-26600fc6ecf9"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["162"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["state=env.encode(3,1,2,0)\n","state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8y2GvnSCm1ru","executionInfo":{"status":"ok","timestamp":1694192193088,"user_tz":-330,"elapsed":442,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"01113aa5-81d9-4d2d-b5cc-e26f4087225f"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["328"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["env.s=state"],"metadata":{"id":"h0G-eFlCm906","executionInfo":{"status":"ok","timestamp":1694192210595,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["env.P[328]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Q8Xmd7xn345","executionInfo":{"status":"ok","timestamp":1694192214224,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"d0b634bd-fb37-4d09-f6b8-8b83de63110d"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: [(1.0, 428, -1, False)],\n"," 1: [(1.0, 228, -1, False)],\n"," 2: [(1.0, 348, -1, False)],\n"," 3: [(1.0, 328, -1, False)],\n"," 4: [(1.0, 328, -10, False)],\n"," 5: [(1.0, 328, -10, False)]}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Solving without RL"],"metadata":{"id":"HdqRMoJ4qqZK"}},{"cell_type":"code","source":["env.s=328\n","steps=0\n","penalties,reward=0,0\n","\n","frames=[]\n","\n","done=False\n","\n","while not done:\n","  action=env.action_space.sample()\n","  state,reward,done,info =env.step(action)\n","\n","  if reward == -10:\n","    penalties+=1\n","\n","  #put each rendered frame into dict for animation\n","\n","  frames.append({'frame': env.render(mode='ansi'),\n","                 'state':state,\n","                 'action':action,\n","                 'reward':reward})\n","\n","  steps+=1\n","\n","\n","print(steps)\n","print(penalties)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"325WAC6-oAsY","executionInfo":{"status":"ok","timestamp":1694192224104,"user_tz":-330,"elapsed":1014,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"644035b3-73a5-4a66-ae49-c2ae51e12ee0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["1521\n","485\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  deprecation(\n"]}]},{"cell_type":"code","source":["#Exploring the environment to get the optimised path\n","from IPython.display import clear_output\n","from time import sleep\n","\n","def print_frames(frames):\n","  for i, frame in enumerate(frames):\n","    clear_output(wait=True)\n","    print(frame['frame'])\n","    print(f\"Timestep:{i+1}\")\n","    print(f\"State:{frame['state']}\")\n","    print(f\"Action:{frame['action']}\")\n","    print(f\"Reward:{frame['reward']}\")\n","    sleep(.1)\n","\n","print_frames(frames)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zx5D4RQkoNaF","executionInfo":{"status":"ok","timestamp":1694193023333,"user_tz":-330,"elapsed":154990,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"6f13aca5-9924-4ee4-b22e-4689dc2a06c7"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n","+---------+\n","  (Dropoff)\n","\n","Timestep:1521\n","State:410\n","Action:5\n","Reward:20\n"]}]},{"cell_type":"markdown","source":["Solving with RL"],"metadata":{"id":"UeTqXue1qyjq"}},{"cell_type":"code","source":["import numpy as np\n","q_table = np.zeros([env.observation_space.n,env.action_space.n])"],"metadata":{"id":"4UOMmK_3o-RQ","executionInfo":{"status":"ok","timestamp":1694192450742,"user_tz":-330,"elapsed":430,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#Training Agent\n","\n","import random\n","from IPython.display import clear_output\n","\n","#Hyper parameters\n","\n","alpha=0.1\n","gamma=0.6\n","epsilon=0.1\n","\n","#For plotting metrics\n","\n","all_epochs=[]\n","all_penalties=[]\n","\n","for i in range(1,100001):\n","  state=env.reset()\n","\n","  epochs,penalties, reward = 0,0,0\n","  done=False\n","\n","  while not done:\n","    if random.uniform(0,1) < epsilon:\n","      action= env.action_space.sample()\n","    else:\n","      action = np.argmax(q_table[state])\n","\n","    next_state,reward,done,info = env.step(action)\n","\n","    old_value= q_table[state,action]\n","\n","    next_max=np.max(q_table[next_state])\n","\n","    new_value = (1-alpha) * old_value + \\\n","                 alpha *(reward +gamma * next_max)\n","\n","    q_table[state,action] = new_value\n","\n","    if reward == -10:\n","      penalties+=1\n","\n","    state= next_state\n","    epochs+=1\n","\n","  if i%100 ==0:\n","    clear_output(wait=True)\n","    print(f\"Episode:{i}\")\n","\n","print(\"Training Finished\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kz1pbXdPpTT_","executionInfo":{"status":"ok","timestamp":1694192552334,"user_tz":-330,"elapsed":88985,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"2f4cbb3c-c117-4034-c099-59e01a23ff7b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode:100000\n","Training Finished\n"]}]},{"cell_type":"code","source":["q_table[328]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XaABSVK1pziF","executionInfo":{"status":"ok","timestamp":1694192565241,"user_tz":-330,"elapsed":427,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"d646cf25-554a-492b-d947-a1aeddfd5c60"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ -2.40855313,  -2.27325184,  -2.40357022,  -2.35686136,\n","       -10.08875108, -10.40283696])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#Evaluate agents performance after q-learning\n","\n","total_epochs, total_penalties = 0,0\n","episodes = 10\n","\n","frames1 = []\n","\n","for episode in range(episodes):\n","  state=env.reset()\n","  epochs,penalties,reward =0,0,0\n","  done =False\n","\n","  while not done:\n","    action=np.argmax(q_table[state])\n","    state,reward,done,info = env.step(action)\n","\n","    if reward == -10:\n","      penalties+=1\n","\n","    epochs+=1\n","\n","    total_penalties +=penalties\n","    total_epochs +=epochs\n","\n","    if episode == 1 :\n","        frames1.append({'frame': env.render(mode='ansi'),'state':state,'action':action,'reward':reward})\n","\n","print(f\"Results after {episodes} episodes:\")\n","print(f\"Average timestpes per episode:{total_epochs/episodes}\")\n","print(f\"Average penalties per episode:{total_penalties/episodes}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHEGi_aPp7Q0","executionInfo":{"status":"ok","timestamp":1694192568845,"user_tz":-330,"elapsed":377,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}},"outputId":"eee4f2fc-ea0b-4b5a-e5e4-c3d4a583ab21"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Results after 10 episodes:\n","Average timestpes per episode:81.9\n","Average penalties per episode:0.0\n"]}]},{"cell_type":"code","source":["print_frames(frames1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V1lGZpYCqYXu","outputId":"70860872-91bb-4ca2-e68f-73d9fc113166","executionInfo":{"status":"ok","timestamp":1694192734781,"user_tz":-330,"elapsed":1474,"user":{"displayName":"Sai Teja . P","userId":"09613603531107672420"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n","+---------+\n","  (Dropoff)\n","\n","Timestep:12\n","State:410\n","Action:5\n","Reward:20\n"]}]}]}